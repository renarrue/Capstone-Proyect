# Versi√≥n FINAL ESTABLE - Usando versiones fijas
import streamlit as st
from langchain_groq import ChatGroq
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.retrievers import BM25Retriever
# --- Importaci√≥n Est√°ndar para EnsembleRetriever (para versi√≥n 0.1.x) ---
from langchain.retrievers import EnsembleRetriever
# --- Fin ---
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
import os

# --- CONFIGURACI√ìN DE LA P√ÅGINA ---
st.set_page_config(page_title="Chatbot Acad√©mico Duoc UC", page_icon="ü§ñ", layout="wide")
st.title("ü§ñ Chatbot del Reglamento Acad√©mico")

# --- CARGA DE LA API KEY DE GROQ ---
GROQ_API_KEY = st.secrets.get("GROQ_API_KEY")

if not GROQ_API_KEY:
    st.error("La clave de API de Groq no est√° configurada. Por favor, agr√©gala a los Secrets de Streamlit.")
    st.stop()

# --- CACHING DE RECURSOS ---
@st.cache_resource
def inicializar_cadena():
    # --- 1. Cargar y Procesar el PDF ---
    loader = PyPDFLoader("reglamento.pdf")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
    docs = loader.load_and_split(text_splitter=text_splitter)

    # --- 2. Crear los Embeddings y el Ensemble Retriever ---
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vector_store = Chroma.from_documents(docs, embeddings)
    vector_retriever = vector_store.as_retriever(search_kwargs={"k": 7})
    bm25_retriever = BM25Retriever.from_documents(docs) # Funciona con v0.0.38
    bm25_retriever.k = 7
    retriever = EnsembleRetriever(retrievers=[bm25_retriever, vector_retriever], weights=[0.7, 0.3])

    # --- 3. Conectarse al Modelo en Groq Cloud ---
    llm = ChatGroq(
        api_key=GROQ_API_KEY,
        model="llama-3.1-8b-instant", # Mantenemos el modelo actual de Groq
        temperature=0.1
    )

    # --- 4. Crear la Cadena de Conversaci√≥n ---
    prompt = ChatPromptTemplate.from_template("""
    INSTRUCCI√ìN PRINCIPAL: Responde SIEMPRE en espa√±ol.
    Eres un asistente experto en el reglamento acad√©mico de Duoc UC. Tu objetivo es dar respuestas claras y precisas basadas √öNICAMENTE en el contexto proporcionado.
    Si la pregunta es general sobre "qu√© debe saber un alumno nuevo", crea un resumen que cubra los puntos clave: Asistencia, Calificaciones para aprobar, y Causas de Reprobaci√≥n.

    CONTEXTO:
    {context}

    PREGUNTA:
    {input}

    RESPUESTA:
    """)
    document_chain = create_stuff_documents_chain(llm, prompt)
    retrieval_chain = create_retrieval_chain(retriever, document_chain)

    return retrieval_chain

# --- L√ìGICA DE LA APLICACI√ìN DE CHAT ---
try:
    retrieval_chain = inicializar_cadena()

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("¬øQu√© duda tienes sobre el reglamento?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Pensando... üí≠"):
                response = retrieval_chain.invoke({"input": prompt})
                st.markdown(response["answer"])

        st.session_state.messages.append({"role": "assistant", "content": response["answer"]})

except Exception as e:
    st.error(f"Ha ocurrido un error durante la ejecuci√≥n: {e}")
    st.exception(e) # Muestra el traceback completo en Streamlit